{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "height": 30
   },
   "source": [
    "# Building a Crew to Prepare for Meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following lines to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Use the animation for pip install\n",
    "# loader = LoadingAnimation()\n",
    "# loader.start(\"Installing\")\n",
    "%pip install -r requirements.txt -q\n",
    "# loader.stop(\"Installation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 608
   },
   "outputs": [],
   "source": [
    "# Create reusable loading animation class\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class LoadingAnimation:\n",
    "    def __init__(self):\n",
    "        self.stop_event = threading.Event()\n",
    "        self.animation_thread = None\n",
    "\n",
    "    def _animate(self, message=\"Loading\"):\n",
    "        chars = \"/â€”\\\\|\"\n",
    "        while not self.stop_event.is_set():\n",
    "            for char in chars:\n",
    "                sys.stdout.write('\\r' + message + '... ' + char)\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(0.1)\n",
    "                if self.stop_event.is_set():\n",
    "                    sys.stdout.write(\"\\n\")\n",
    "                    break\n",
    "\n",
    "    def start(self, message=\"Loading\"):\n",
    "        self.stop_event.clear()\n",
    "        self.animation_thread = threading.Thread(target=self._animate, args=(message,))\n",
    "        self.animation_thread.daemon = True\n",
    "        self.animation_thread.start()\n",
    "\n",
    "    def stop(self, completion_message=\"Complete\"):\n",
    "        self.stop_event.set()\n",
    "        if self.animation_thread:\n",
    "            self.animation_thread.join()\n",
    "        print(f\"\\r{completion_message} âœ“\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Define a fake `load_dotenv` function\n",
    "def _load_dotenv(*args, **kwargs):\n",
    "    env_path = kwargs.get('dotenv_path', '.env')  # Default to '.env'\n",
    "    parsed_env = dotenv_values(env_path)\n",
    "\n",
    "    # Manually set valid key-value pairs\n",
    "    for key, value in parsed_env.items():\n",
    "        if key and value:  # Check for valid key-value pairs\n",
    "            os.environ[key] = value\n",
    "\n",
    "dotenv.load_dotenv = _load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Setup\n",
    "Initial imports for the CrewAI Flow and Crew and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/_internal/_config.py:291: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/opt/conda/lib/python3.12/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"website_url\")\n",
      "/opt/conda/lib/python3.12/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"website_url\")\n",
      "/opt/conda/lib/python3.12/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool\n",
    "\n",
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 812
   },
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/agents.yml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/tasks.yml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "# Define the agents for our meeting preparation crew\n",
    "researcher = Agent(\n",
    "    role=agents_config['researcher']['role'],\n",
    "    goal=agents_config['researcher']['goal'],\n",
    "    backstory=agents_config['researcher']['backstory'],\n",
    "    verbose=True,\n",
    "    tools=[SerperDevTool(), ScrapeWebsiteTool()]  # Web search and document analysis tools\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    role=agents_config['analyst']['role'],\n",
    "    goal=agents_config['analyst']['goal'],\n",
    "    backstory=agents_config['analyst']['backstory'],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define the tasks for our crew\n",
    "research_task = Task(\n",
    "    description=tasks_config['research_task']['description'],\n",
    "    expected_output=tasks_config['research_task']['expected_output'],\n",
    "    agent=researcher,\n",
    ")\n",
    "\n",
    "preparation_task = Task(\n",
    "    description=tasks_config['preparation_task']['description'],\n",
    "    expected_output=tasks_config['preparation_task']['expected_output'],\n",
    "    agent=analyst,\n",
    "    output_file=\"output/meeting_brief.md\"\n",
    ")\n",
    "\n",
    "# Create the crew\n",
    "meeting_prep_crew = Crew(\n",
    "    agents=[researcher, analyst],\n",
    "    tasks=[research_task, preparation_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 20:36:55,429 - 281472977881920 - llm.py-llm:388 - ERROR: LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing for meeting about: A sprint retrospective\n",
      "Participants: macy@okta.com\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][ðŸš€ CREW 'CREW' STARTED, 5B2E0249-2974-407E-9F95-F97D04695806]: 2025-03-14 20:36:55.409544\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][ðŸ“‹ TASK STARTED: CONDUCT STRATEGIC INTELLIGENCE GATHERING ON THE UPCOMING MEETING ABOUT A SPRINT RETROSPECTIVE WITH MACY@OKTA.COM.\n",
      "YOUR OBJECTIVE IS TO UNCOVER INSIGHTS THAT WILL GIVE OUR EXECUTIVE A COMPETITIVE ADVANTAGE:\n",
      "1. TOPIC ANALYSIS:\n",
      "   - CORE BUSINESS IMPLICATIONS OF A SPRINT RETROSPECTIVE\n",
      "   - LATEST DEVELOPMENTS AND EMERGING TRENDS (WITHIN LAST 3 MONTHS)\n",
      "   - COMPETITIVE LANDSCAPE AND MARKET POSITION\n",
      "\n",
      "2. PARTICIPANT INTELLIGENCE:\n",
      "   - PROFESSIONAL BACKGROUND AND CURRENT ROLE OF EACH PARTICIPANT\n",
      "   - RECENT STATEMENTS, PUBLICATIONS, OR POSITIONS ON A SPRINT RETROSPECTIVE\n",
      "   - PERSONAL COMMUNICATION STYLE AND DECISION-MAKING PATTERNS\n",
      "   - RELATIONSHIPS WITH OTHER PARTICIPANTS (ALLIANCES, TENSIONS)\n",
      "\n",
      "3. STRATEGIC CONTEXT:\n",
      "   - IDENTIFY POTENTIAL HIDDEN AGENDAS OR UNSTATED OBJECTIVES\n",
      "   - MAP POTENTIAL AREAS OF ALIGNMENT AND CONFLICT\n",
      "   - HIGHLIGHT POLITICAL OR ORGANIZATIONAL DYNAMICS AT PLAY\n",
      "\n",
      "FOCUS ON QUALITY OVER QUANTITY. PRIORITIZE INFORMATION THAT DIRECTLY IMPACTS MEETING OBJECTIVES.\n",
      "]: 2025-03-14 20:36:55.414272\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][ðŸ¤– AGENT 'SENIOR MEETING INTELLIGENCE SPECIALIST FOCUSING ON EXECUTIVE-LEVEL PREPARATION\n",
      "' STARTED TASK]: 2025-03-14 20:36:55.415123\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Meeting Intelligence Specialist focusing on executive-level preparation\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mConduct strategic intelligence gathering on the upcoming meeting about A sprint retrospective with macy@okta.com.\n",
      "Your objective is to uncover insights that will give our executive a competitive advantage:\n",
      "1. Topic analysis:\n",
      "   - Core business implications of A sprint retrospective\n",
      "   - Latest developments and emerging trends (within last 3 months)\n",
      "   - Competitive landscape and market position\n",
      "\n",
      "2. Participant intelligence:\n",
      "   - Professional background and current role of each participant\n",
      "   - Recent statements, publications, or positions on A sprint retrospective\n",
      "   - Personal communication style and decision-making patterns\n",
      "   - Relationships with other participants (alliances, tensions)\n",
      "\n",
      "3. Strategic context:\n",
      "   - Identify potential hidden agendas or unstated objectives\n",
      "   - Map potential areas of alignment and conflict\n",
      "   - Highlight political or organizational dynamics at play\n",
      "\n",
      "Focus on quality over quantity. Prioritize information that directly impacts meeting objectives.\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][ðŸ¤– LLM CALL STARTED]: 2025-03-14 20:36:55.415290\u001b[00m\n",
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][âŒ LLM CALL FAILED: 'LITELLM.AUTHENTICATIONERROR: AUTHENTICATIONERROR: OPENAIEXCEPTION - THE API_KEY CLIENT OPTION MUST BE SET EITHER BY PASSING API_KEY TO THE CLIENT OR BY SETTING THE OPENAI_API_KEY ENVIRONMENT VARIABLE']: 2025-03-14 20:36:55.429905\u001b[00m\n",
      "\u001b[91m Error during LLM call: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[00m\n",
      "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
      "\u001b[91m Error details: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][âŒ TASK FAILED: CONDUCT STRATEGIC INTELLIGENCE GATHERING ON THE UPCOMING MEETING ABOUT A SPRINT RETROSPECTIVE WITH MACY@OKTA.COM.\n",
      "YOUR OBJECTIVE IS TO UNCOVER INSIGHTS THAT WILL GIVE OUR EXECUTIVE A COMPETITIVE ADVANTAGE:\n",
      "1. TOPIC ANALYSIS:\n",
      "   - CORE BUSINESS IMPLICATIONS OF A SPRINT RETROSPECTIVE\n",
      "   - LATEST DEVELOPMENTS AND EMERGING TRENDS (WITHIN LAST 3 MONTHS)\n",
      "   - COMPETITIVE LANDSCAPE AND MARKET POSITION\n",
      "\n",
      "2. PARTICIPANT INTELLIGENCE:\n",
      "   - PROFESSIONAL BACKGROUND AND CURRENT ROLE OF EACH PARTICIPANT\n",
      "   - RECENT STATEMENTS, PUBLICATIONS, OR POSITIONS ON A SPRINT RETROSPECTIVE\n",
      "   - PERSONAL COMMUNICATION STYLE AND DECISION-MAKING PATTERNS\n",
      "   - RELATIONSHIPS WITH OTHER PARTICIPANTS (ALLIANCES, TENSIONS)\n",
      "\n",
      "3. STRATEGIC CONTEXT:\n",
      "   - IDENTIFY POTENTIAL HIDDEN AGENDAS OR UNSTATED OBJECTIVES\n",
      "   - MAP POTENTIAL AREAS OF ALIGNMENT AND CONFLICT\n",
      "   - HIGHLIGHT POLITICAL OR ORGANIZATIONAL DYNAMICS AT PLAY\n",
      "\n",
      "FOCUS ON QUALITY OVER QUANTITY. PRIORITIZE INFORMATION THAT DIRECTLY IMPACTS MEETING OBJECTIVES.\n",
      "]: 2025-03-14 20:36:55.430505\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-14 20:36:55][âŒ CREW 'CREW' FAILED, 5B2E0249-2974-407E-9F95-F97D04695806]: 2025-03-14 20:36:55.430541\u001b[00m\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/llms/openai/openai.py:711\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/llms/openai/openai.py:614\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    612\u001b[0m         status_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m422\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax retries must be an int\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n\u001b[0;32m--> 614\u001b[0m openai_client: OpenAI \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_openai_client(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     is_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    616\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    617\u001b[0m     api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m    618\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mapi_version,\n\u001b[1;32m    619\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    620\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    621\u001b[0m     organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m    622\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[1;32m    623\u001b[0m )\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/llms/openai/openai.py:368\u001b[0m, in \u001b[0;36mOpenAIChatCompletion._get_openai_client\u001b[0;34m(self, is_async, api_key, api_base, api_version, timeout, max_retries, organization, client)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     _new_client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m    369\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    370\u001b[0m         base_url\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m    371\u001b[0m         http_client\u001b[38;5;241m=\u001b[39mlitellm\u001b[38;5;241m.\u001b[39mclient_session,\n\u001b[1;32m    372\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    373\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    374\u001b[0m         organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m## SAVE CACHE KEY\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_client.py:114\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/main.py:1692\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1688\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1689\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1690\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[1;32m   1691\u001b[0m     )\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/main.py:1665\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1665\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai_chat_completions\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[1;32m   1666\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1667\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1668\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1669\u001b[0m         model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m   1670\u001b[0m         print_verbose\u001b[38;5;241m=\u001b[39mprint_verbose,\n\u001b[1;32m   1671\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1672\u001b[0m         api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   1673\u001b[0m         acompletion\u001b[38;5;241m=\u001b[39macompletion,\n\u001b[1;32m   1674\u001b[0m         logging_obj\u001b[38;5;241m=\u001b[39mlogging,\n\u001b[1;32m   1675\u001b[0m         optional_params\u001b[38;5;241m=\u001b[39moptional_params,\n\u001b[1;32m   1676\u001b[0m         litellm_params\u001b[38;5;241m=\u001b[39mlitellm_params,\n\u001b[1;32m   1677\u001b[0m         logger_fn\u001b[38;5;241m=\u001b[39mlogger_fn,\n\u001b[1;32m   1678\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m         custom_prompt_dict\u001b[38;5;241m=\u001b[39mcustom_prompt_dict,\n\u001b[1;32m   1680\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,  \u001b[38;5;66;03m# pass AsyncOpenAI, OpenAI client\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m         organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m   1682\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   1683\u001b[0m     )\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/llms/openai/openai.py:721\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 721\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    722\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39merror_text, headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[1;32m    723\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParticipants: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticipants\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the crew with the provided inputs\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m meeting_prep_crew\u001b[38;5;241m.\u001b[39mkickoff(inputs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: meeting_topic,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipants\u001b[39m\u001b[38;5;124m\"\u001b[39m: participants\n\u001b[1;32m     12\u001b[0m })\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMeeting brief has been saved to output/meeting_brief.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Display the markdown content in a formatted way\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/crew.py:619\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 619\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sequential_process()\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    621\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/crew.py:731\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    730\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_tasks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/crew.py:829\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    826\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    828\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 829\u001b[0m task_output \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mexecute_sync(\n\u001b[1;32m    830\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent_to_use,\n\u001b[1;32m    831\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    832\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_for_task,\n\u001b[1;32m    833\u001b[0m )\n\u001b[1;32m    834\u001b[0m task_outputs\u001b[38;5;241m.\u001b[39mappend(task_output)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/task.py:304\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    299\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    302\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_core(agent, context, tools)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/task.py:448\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    447\u001b[0m crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/task.py:368\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[1;32m    367\u001b[0m crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context\u001b[38;5;241m=\u001b[39mcontext))\n\u001b[0;32m--> 368\u001b[0m result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mexecute_task(\n\u001b[1;32m    369\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    370\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    371\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    374\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    375\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    376\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    377\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    384\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agent.py:265\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         event\u001b[38;5;241m=\u001b[39mAgentExecutionErrorEvent(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         ),\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agent.py:246\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     crewai_event_bus\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    239\u001b[0m         event\u001b[38;5;241m=\u001b[39mAgentExecutionStartedEvent(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m         ),\n\u001b[1;32m    245\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    247\u001b[0m         {\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_prompt,\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names,\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description,\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mhuman_input,\n\u001b[1;32m    252\u001b[0m         }\n\u001b[1;32m    253\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:119\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_unknown_error(e)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:108\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    111\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:166\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_context_length_exceeded(e):\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_context_length()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:146\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_rpm_limit()\n\u001b[0;32m--> 146\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_llm_response()\n\u001b[1;32m    147\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_llm_response(answer)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:216\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    213\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     )\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    220\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:207\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m    209\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    213\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/crewai/llm.py:310\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    307\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# --- 2) Make the completion call\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    311\u001b[0m response_message \u001b[38;5;241m=\u001b[39m cast(Choices, cast(ModelResponse, response)\u001b[38;5;241m.\u001b[39mchoices)[\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    313\u001b[0m ]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    314\u001b[0m text_response \u001b[38;5;241m=\u001b[39m response_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/utils.py:1154\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1151\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1152\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1153\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/utils.py:1032\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/main.py:3068\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   3066\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3067\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3068\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   3069\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   3070\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   3071\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   3072\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   3073\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   3074\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2201\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:357\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[1;32m    355\u001b[0m ):\n\u001b[1;32m    356\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[1;32m    358\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    360\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    361\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    362\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMistral API raised a streaming error\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[1;32m    365\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# If inputs are not provided, ask for them\n",
    "meeting_topic = input(\"Enter the meeting topic: \")\n",
    "participants = input(\"Enter the meeting participants: \")\n",
    "\n",
    "print(f\"\\nPreparing for meeting about: {meeting_topic}\")\n",
    "print(f\"Participants: {participants}\\n\")\n",
    "\n",
    "# Run the crew with the provided inputs\n",
    "result = meeting_prep_crew.kickoff(inputs={\n",
    "    \"topic\": meeting_topic,\n",
    "    \"participants\": participants\n",
    "})\n",
    "\n",
    "print(\"\\n\\nMeeting brief has been saved to output/meeting_brief.md\")\n",
    "# Display the markdown content in a formatted way\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Display the raw result as formatted markdown\n",
    "display(Markdown(result.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
